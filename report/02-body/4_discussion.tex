\chapter{Discussion}
\label{chap:discussion}


\subsection{Constatations}
\todo{
At the edge of technologies and sot
we are only using techs release in late 2019
}

\section{Convex Dataset}
\subsection{Data augmentation}
Example:

Who is the author of the Harry Potter series? OR Who wrote Harry Potter?
What was the year of publication for the first book? OR When was it first published?
Title of the first book? OR The first book was called what?
What country was the book set in? OR It was set in what country?
Which book has the highest page count? OR What's the longest book?


\subsection{Human errors}
Mechanical Truck gathering mistakes during the dataset building due to humans not respecting the standard format. Implying 32 wrong question-answers for a single mistake.
When did the first The Fast and the Furious film come out?
TO "answer": \url{"https://www.wikidata.org/wiki/Q155476"} instead of 22 June 2001
however: "answer\_text": "The first film came out 22 June 2001."

\subsection{Data inconstancy}
"question": "When was he born?",
"answer\_text": "1 August 1819" same as answer

Sometimes it is binary, and some times it is in \gls{nl}

"question": "When was it published?", 
"answer\_text": "The book came out 30 June 1997 in the UK."

This is an important inconstancy biaises for training.

\subsection{Wrong answers}
When did the first The Fast and the Furious film come out?

GraphQA answers 1955, which is the date of publication of the original The Fast and the Furious movie. And non of the competing qa systems answer correctly to the question, neither to the provided false answer, neither the correct one.

We didn't take time to go thru the whole dataset because time was missing, but funnily, GraphQA most often triggered warnings when the dataset had such errors, that's why we saw them.

This all implies that GraphQA, could even perform better than the concurrents, but more exhaustive evaluations on additional datasets are required. But in the current version GraphQA is very time and computing resources consuming, which made it hard to evaluated it on multiple datasets in parallel to development 


\subsection{Don't trust Mechanical Trucks}
response format not respected \url{"https://www.wikidata.org/wiki/Q5951550?wprov=srpw1\_0"} instead of \url{"https://www.wikidata.org/wiki/Q5951550"}

How tall is Avril Lavigne? -> (157 centimetre) additionally to the spelling mistake and a none standard format for the answer has the centimeter information is considered has a unit qualifier to the value 157, which must be the answer in this case, by checking the latest version of wikidata we couldn't find any spo containing the information.


\section{What we learned from the project}
\subsection{Only trust yourself}
Preprints: some good and mostly bad
Published articles: some good, but mostly interative research with name dropping
Published in conferences: some good, but be careful at where it is published, china is worrying
Sadly everything looks alike with time
Never trust what's written, always cross check the results and the given datasets or code if any
Be critique with state-of-the-art and baseline clams as long as it was not reproduced.



\section{What happens}

Conversational,
It tests each conversation with convex and graphqa as extension.
Note that if no initial answer if found, no graph is built for platypus or qanswer, which skips the graph extension, as it's part of the nature of GraphQA and Convex


\section{CONVEX}
Terrible at many levels.

We knew we started that the intial answer part was bad, but the results shown were still proimising. At the end we noticed that it was bullshit, as we couldn't reproduce the results in the paper, and even after contacting the author we got the confirmation that the results where not reproducable has expected as the best part of the paper was written for motivatitional purposed, but we didn't understand it that way at first.

However, as a result we had no choice to go with it, and take the best of what we got so far, as it was too late to step back and take another approach by redesigning the whole process. 
So we built from scratch a system fully based on sub-graphs, see chapter GRAPHQA.

Contacted the author and debugged his code together at first, then we decided to fork the project and continue on our own by fixing and adapting the code to our needs as GraphQA progressed.



\section{Questions left}
\todo{
It would be interesting to see if the machine becomes sophist with our algorithm.
}


In another work, we would like to explore the possibilities of merging these two modules, and evaluate if it's pertinent.

Another question would be toward generalization, does generalisation needs to be only one and unique module able to do everything or can it be a clever composition of modules. Or does it need a specific module which is lightweight and able to generalise the tasks to send to the right module, as a coordinator.

Explore the possibilities to combine sub-graphs to keep context and history of the conversation and been able to connect facts from various subjects together and summarise them cleverly.

Say that sub-graphs could be pre generated to specific contextes, like news articles, and a module linking the initial question to a predefined sub-graph is possible.

Sub-graphs can also be generate manually by news authors by using keywords and sub-graphs linking, or automatically. 


\subsection{Subgraphs}
\todo{
Try to find a correlation between human thinking / reasoning the numerical knowledge graph representation, compared to IR, access structure, or even algorithms.
}

\section{Convex}
\todo{
Results returned are often pure luck, as if multiple objects are present in for the same subject and predicate, convex will return the first one. Additionally, as the NER depends on TAGME, it is up to them to return the right entities for entities with the same name in the wikipedia. Same when CONVEX do a web search.

PROBABLY NOT Results are choatic, as randomness is possible during the IR operation done with TAGME, and particularly when retrive
}




